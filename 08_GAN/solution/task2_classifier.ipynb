{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9ca6cd",
   "metadata": {},
   "source": [
    "# Task2 - Classifier\n",
    "This jupyter notebook contains the code for training a CNN based classifier on CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b01e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as trafos\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b0fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "batch_size=64\n",
    "trafo_train = trafos.Compose([trafos.RandomHorizontalFlip(),\n",
    "                        trafos.ToTensor(), trafos.Resize(32), trafos.Normalize((0.5), (0.5))])\n",
    "trafo_test = trafos.Compose([trafos.ToTensor(), trafos.Resize(32), trafos.Normalize((0.5), (0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=\"datasets\", train=True, download=True, transform=trafo_train)\n",
    "testset = torchvision.datasets.FashionMNIST(root=\"datasets\", train=False, download=True, transform=trafo_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=16, drop_last=False, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, num_workers=16, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23f8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN for classification\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, nf=64, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        block = [nn.Conv2d(1, nf, kernel_size=3, stride=1, padding=1), nn.BatchNorm2d(nf), nn.LeakyReLU(0.2, True),\n",
    "                nn.Conv2d(nf, nf*2, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(nf*2), nn.LeakyReLU(0.2, True),\n",
    "                nn.Conv2d(nf*2, nf*4, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(nf*4), nn.LeakyReLU(0.2, True),\n",
    "                nn.Conv2d(nf*4, nf*4, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(nf*4), nn.LeakyReLU(0.2, True)]\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "        feature = [nn.Linear(nf*4, 100), nn.LeakyReLU(0.2, True)]\n",
    "        self.feature = nn.Sequential(*feature)\n",
    "\n",
    "        self.final = nn.Linear(100, num_classes)\n",
    "\n",
    "    #use our classifer weights as feature extractor\n",
    "    def get_features(self, x):\n",
    "        x = self.block(x)\n",
    "        x = torch.mean(x, dim=(2,3))\n",
    "        return self.feature(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.get_features(x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0375ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier has 1.733M parameters\n"
     ]
    }
   ],
   "source": [
    "def print_parameters(net, name):\n",
    "    num_params = 0\n",
    "    for p in net.parameters():\n",
    "        num_params += p.numel()\n",
    "    \n",
    "    print(\"{} has {:.3f}M parameters\".format(name, num_params/1e6))\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "classifier = Classifier().to(device)\n",
    "print_parameters(classifier, \"Classifier\")\n",
    "\n",
    "lr = 1e-4\n",
    "optim = torch.optim.Adam(classifier.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "033ec1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1. (Time taken: 9.944s)\n",
      "End of epoch 2. (Time taken: 14.720s)\n",
      "End of epoch 3. (Time taken: 11.332s)\n",
      "End of epoch 4. (Time taken: 11.246s)\n",
      "End of epoch 5. (Time taken: 10.890s)\n",
      "End of epoch 6. (Time taken: 10.895s)\n",
      "End of epoch 7. (Time taken: 12.518s)\n",
      "End of epoch 8. (Time taken: 12.881s)\n",
      "End of epoch 9. (Time taken: 15.645s)\n",
      "End of epoch 10. (Time taken: 18.293s)\n",
      "End of epoch 11. (Time taken: 16.362s)\n",
      "End of epoch 12. (Time taken: 13.164s)\n",
      "End of epoch 13. (Time taken: 10.388s)\n",
      "End of epoch 14. (Time taken: 10.899s)\n",
      "End of epoch 15. (Time taken: 12.339s)\n",
      "End of epoch 16. (Time taken: 11.186s)\n",
      "End of epoch 17. (Time taken: 12.709s)\n",
      "End of epoch 18. (Time taken: 8.556s)\n",
      "End of epoch 19. (Time taken: 12.482s)\n",
      "End of epoch 20. (Time taken: 12.003s)\n",
      "End of epoch 21. (Time taken: 12.062s)\n",
      "End of epoch 22. (Time taken: 12.527s)\n",
      "End of epoch 23. (Time taken: 11.788s)\n",
      "End of epoch 24. (Time taken: 11.405s)\n",
      "End of epoch 25. (Time taken: 12.820s)\n",
      "End of epoch 26. (Time taken: 5.981s)\n",
      "End of epoch 27. (Time taken: 8.493s)\n",
      "End of epoch 28. (Time taken: 6.057s)\n",
      "End of epoch 29. (Time taken: 11.096s)\n",
      "End of epoch 30. (Time taken: 11.997s)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epoch_decay = 10\n",
    "num_epochs = 30\n",
    "\n",
    "losses_avg_train = []\n",
    "losses_avg_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    start = time.time()\n",
    "    #train\n",
    "    classifier.train()\n",
    "    cur_losses = []\n",
    "    num_total = 0\n",
    "    num_right = 0\n",
    "    for it,data in enumerate(trainloader):\n",
    "        images, targets = data\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        out = classifier(images)\n",
    "        loss = criterion(out, targets)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        _, pred = out.max(1)\n",
    "        num_total += images.size(0)\n",
    "        num_right += torch.sum(torch.eq(pred, targets)).cpu().numpy()\n",
    "        \n",
    "        cur_losses.append(loss.item())\n",
    "        \n",
    "    losses_avg_train.append(np.mean(cur_losses))\n",
    "    acc_train.append(num_right/num_total*100.0)\n",
    "    \n",
    "    \n",
    "    #test\n",
    "    classifier.eval()\n",
    "    cur_losses = []\n",
    "    num_total = 0\n",
    "    num_right = 0\n",
    "    for it,data in enumerate(testloader):\n",
    "        images, targets = data\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        out = classifier(images)\n",
    "        loss = criterion(out, targets)\n",
    "        \n",
    "        cur_losses.append(loss.item())\n",
    "        \n",
    "        _, pred = out.max(1)\n",
    "        num_total += images.size(0)\n",
    "        num_right += torch.sum(torch.eq(pred, targets)).cpu().numpy()\n",
    "        \n",
    "    losses_avg_test.append(np.mean(cur_losses))\n",
    "    acc_test.append(num_right/num_total*100.0)\n",
    "    \n",
    "    #plot losses\n",
    "    plt.figure(dpi=300)\n",
    "    plt.title(\"Classification Losses\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(np.arange(1, epoch+1), losses_avg_train, label=\"Train\")\n",
    "    plt.plot(np.arange(1, epoch+1), losses_avg_test, label=\"Test\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"losses_classifier.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(dpi=300)\n",
    "    plt.title(\"Classification Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy [%]\")\n",
    "    plt.plot(np.arange(1, epoch+1), acc_train, label=\"Train\")\n",
    "    plt.plot(np.arange(1, epoch+1), acc_test, label=\"Test\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"accuracy_classifier.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    #save model\n",
    "    if acc_test[-1]>best_acc:\n",
    "        best_acc = acc_test[-1]\n",
    "        torch.save(classifier.state_dict(), \"classifier.ckpt\")\n",
    "    \n",
    "    #anneal learning rate\n",
    "    nlrg = lr*(1.0-max(0,epoch-epoch_decay)/float(num_epochs-epoch_decay+1)) #new learning rate\n",
    "    if epoch>epoch_decay: #decay learning rate linearly\n",
    "        for param_group in optim.param_groups:\n",
    "            param_group['lr'] = nlrg\n",
    "    \n",
    "    print(\"End of epoch {}. (Time taken: {:.3f}s)\".format(epoch, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a6118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
