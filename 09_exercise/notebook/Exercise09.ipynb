{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y488QNTzaYga"
      },
      "source": [
        "## Exercise Sheet 1: Recurrent Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yI-QNP6aYgb"
      },
      "source": [
        "Compare Vanilla Recurrent Neural Networks (RNN) with Long-Short Term Networks (LSTM). Implement a vanilla RNN and LSTM from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toSLZLFpaYgb"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import sys\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.functional as F\n",
        "\n",
        "# import RNN from torch\n",
        "from torch.nn import RNN\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# set seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# set paths\n",
        "data_path = 'data/'\n",
        "model_path = 'model/'\n",
        "results_path = 'results/'\n",
        "\n",
        "# make directories if they don't exist\n",
        "if not os.path.exists(data_path):\n",
        "    os.makedirs(data_path)\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "if not os.path.exists(results_path):\n",
        "    os.makedirs(results_path)\n",
        "\n",
        "\n",
        "# Data\n",
        "p1 = [5, 10, 15, 20]\n",
        "p2_acc_rnn = []\n",
        "p3_acc_lstm = []\n",
        "\n",
        "# Hyperparameters\n",
        "config = {\n",
        "    \"input_length\": 12,\n",
        "    \"input_dim\": 1,\n",
        "    \"num_classes\": 10,\n",
        "    \"num_hidden\": 128,\n",
        "    \"batch_size\": 128,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"train_steps\": 10000,\n",
        "    \"test_steps\": 100,\n",
        "    \"max_norm\": 10.0\n",
        "}\n",
        "\n",
        "# save config\n",
        "with open(model_path + 'config.json', 'w') as file:\n",
        "    json.dump(config, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL8R6mBoaYgc"
      },
      "source": [
        "### Task 1: Toy Problem: Palindrome Numbers\n",
        "\n",
        "Use a  a recurrent neural network to predict the next digit of the palindrome\n",
        "at every timestep. This can become difficult for very long sequences since the network has to memorise information from very far away earlier timesteps. Goal is to study the memoization capability of recurrent networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gd9cfUdaYgc"
      },
      "outputs": [],
      "source": [
        "class PalindromeDataset(data.Dataset):\n",
        "    \"\"\" Randomly generates palindromes of a given length.\n",
        "        The input is the first N-1 digits of the palindrome, the target is the last digit.\n",
        "        For short palindromes, the number of possible palindromes is limited.\n",
        "    \"\"\"\n",
        "    def __init__(self, seq_length):\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of possible palindroms can be very big:\n",
        "        # (10**(seq_length/2) or (10**((seq_length+1)/2)\n",
        "        # Therefore we return the maximum integer value\n",
        "        return sys.maxsize\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Keep last digit as target label. Note: one-hot encoding for inputs is\n",
        "        # more suitable for training, but this also works.\n",
        "        full_palindrome = self.generate_palindrome()\n",
        "        # Split palindrome into inputs (N-1 digits) and target (1 digit)\n",
        "        return full_palindrome[0:-1], int(full_palindrome[-1])\n",
        "\n",
        "    def generate_palindrome(self):\n",
        "        # Generates a single, random palindrome number of 'length' digits.\n",
        "        left = [np.random.randint(0, 10) for _ in range(math.ceil(self.seq_length / 2))]\n",
        "        left = np.asarray(left, dtype=np.float32)\n",
        "        right = np.flip(left, 0) if self.seq_length % 2 == 0 else np.flip(left[:-1], 0)\n",
        "        return np.concatenate((left, right))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dApesI6gaYgc"
      },
      "outputs": [],
      "source": [
        "class VanillaRNN(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, seq_length, input_dim, num_hidden, num_classes, batch_size, device=None):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "        self.seq_length = seq_length\n",
        "        self.input_dim = input_dim\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        if device is None:\n",
        "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # Define the RNN layer\n",
        "        self.hidden_state = torch.zeros(self.batch_size, self.num_hidden)\n",
        "        self.W_hx = nn.Parameter(torch.Tensor(self.input_dim, self.num_hidden))      # input to hidden\n",
        "        self.W_hh = nn.Parameter(torch.Tensor(self.num_hidden, self.num_hidden))     # hidden to hidden\n",
        "        self.B_h = nn.Parameter(torch.Tensor(self.num_hidden))                       # hidden bias\n",
        "        # Define the output layer\n",
        "        self.W_ph = nn.Parameter(torch.Tensor(self.num_hidden, self.num_classes))    # hidden to output\n",
        "        self.B_y = nn.Parameter(torch.Tensor(self.num_classes))                      # output bias\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state\n",
        "        h_t = torch.zeros(self.num_hidden)\n",
        "\n",
        "        for t in range(self.seq_length): # iterate over the time steps\n",
        "            x_t = x[:, t].view(128,-1)\n",
        "            h_t = torch.tanh(x_t @ self.W_hx + h_t @ self.W_hh + self.B_h)\n",
        "\n",
        "        output = h_t @ self.W_ph + self.B_y\n",
        "        y = torch.softmax(output, dim=1)\n",
        "        return y\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\" Keep weights in a similar range to avoid\n",
        "            gradients vanishing or exploding.\n",
        "        \"\"\"\n",
        "        # Initialize weights\n",
        "        nn.init.xavier_normal_(self.W_hx)\n",
        "        nn.init.xavier_normal_(self.W_hh)\n",
        "        nn.init.xavier_normal_(self.W_ph)\n",
        "        nn.init.zeros_(self.B_h)\n",
        "        nn.init.zeros_(self.B_y)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Initialize hidden state\n",
        "        self.hidden_state = torch.zeros(self.batch_size, self.num_hidden, device=self.device)\n",
        "\n",
        "    def set_grad(self, requires_grad):\n",
        "        # Set requires_grad for all parameters\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEZQlYWgaYgc"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(outputs, targets):\n",
        "    \"\"\" Compute the accuracy of the model's predictions.\"\"\"\n",
        "    # Compute accuracy of outputs compared to targets\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = predicted.eq(targets)\n",
        "    return 100 * correct.sum().item() / targets.size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feuYF0l0aYgc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(config:json, input_length=5, type='RNN', device=None):\n",
        "    \"\"\" Train the model on the training set.\n",
        "        Returns the trained model, losses and accuracies.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    if input_length == 0:\n",
        "        input_length = config['input_length']\n",
        "\n",
        "    # Initialize the model that we are going to use\n",
        "    if type == 'RNN':\n",
        "        model = VanillaRNN(input_length, config['input_dim'], config['num_hidden'], config['num_classes'], config['batch_size'], device=device)\n",
        "    elif type == 'LSTM':\n",
        "        model = LSTM(input_length, config['input_dim'], config['num_hidden'], config['num_classes'], config['batch_size'], device=device)\n",
        "    else:\n",
        "        raise ValueError('Model type not supported')\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Initialize the dataset and data loader (note the +1)\n",
        "    dataset = PalindromeDataset(input_length + 1)\n",
        "    data_loader = data.DataLoader(dataset, config['batch_size'], shuffle=True, num_workers=0)\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    loss = 0.0\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(data_loader, 0):\n",
        "\n",
        "        # Only for time measurement of step through network\n",
        "        t1 = time.time()\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass, backward pass, and optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Clip gradients to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=config['max_norm'])\n",
        "\n",
        "        loss += loss.item()\n",
        "        accuracy = 0.0\n",
        "\n",
        "        # Print statistics\n",
        "        if i % 10 == 0:\n",
        "            # Just for time measurement\n",
        "            t2 = time.time()\n",
        "            # print accuracy/loss here\n",
        "            accuracy = compute_accuracy(outputs, targets)\n",
        "            accuracies.append(accuracy)\n",
        "            print('[step: %5d] loss: %.4f acc: %.4f time: %5d' %\n",
        "                          (i, loss / 10, accuracy, t2-t1 / 10))\n",
        "            losses.append(loss.detach().numpy() / 10)\n",
        "            loss = 0.0\n",
        "\n",
        "        if i == config['train_steps']:\n",
        "            # If you receive a PyTorch data-loader error, check this bug report:\n",
        "            # https://github.com/pytorch/pytorch/pull/9655\n",
        "            break\n",
        "\n",
        "    print('Finished Training')\n",
        "    return model, losses, accuracies\n",
        "\n",
        "\n",
        "def test(model, config:json, input_length=5, device=None):\n",
        "    \"\"\" Test the model on the test set.\n",
        "        Returns the accuracies.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    if input_length == 0:\n",
        "        input_length = config['input_length']\n",
        "\n",
        "    # Initialize the dataset and data loader (leave the +1)\n",
        "    dataset = PalindromeDataset(input_length+1)\n",
        "    data_loader = data.DataLoader(dataset, config['batch_size'], shuffle=True, num_workers=0)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Test the model\n",
        "    accuracies = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(data_loader, 0):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            accuracy = 0.0\n",
        "            if i % 10 == 0:\n",
        "                accuracy = compute_accuracy(outputs, targets)\n",
        "                accuracies.append(accuracy)\n",
        "                print('Accuracy: %.4f' % accuracy)\n",
        "\n",
        "            if i == config['test_steps']:\n",
        "                break\n",
        "\n",
        "    print('Finished Testing')\n",
        "    return accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNY4H1xLaYgd"
      },
      "outputs": [],
      "source": [
        "# Load the configuration\n",
        "with open(model_path + 'config.json', 'r') as file:\n",
        "    config = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odpln9HRaYgd"
      },
      "outputs": [],
      "source": [
        "def plot_loss(losses, title='Training Loss', path=None):\n",
        "    \"\"\" Plot the losses of the model.\"\"\"\n",
        "    if path is None:\n",
        "        path = results_path + 'training_loss.png'\n",
        "    plt.plot(losses)\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(title)\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n",
        "\n",
        "def plot_accuracy(accuracies, title='Training Accuracy', path=None):\n",
        "    \"\"\" Plot the accuracies of the model.\"\"\"\n",
        "    if path is None:\n",
        "        path = results_path + 'training_accuracy.png'\n",
        "    plt.plot(accuracies)\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title(title)\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cpWmPvKaYgd"
      },
      "source": [
        "#### Train and evaluate model on Palindromes with length N = 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zx0OwoLaYgd"
      },
      "outputs": [],
      "source": [
        "# Train the model on T=5\n",
        "model, losses, accuracies = train(config, input_length=p1[0], type='RNN', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko83h3P7aYgd"
      },
      "outputs": [],
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss [N=5]', path=results_path + 'training_loss_5_rnn.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP1mGLUJaYgd"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(accuracies, title='Training Accuracy [N=5]', path=results_path + 'training_accuracy_5_rnn.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OouiYC_aYgd"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[0], config=config, device=device)\n",
        "# Add accuracies\n",
        "p2_acc_rnn.append(np.mean(test_accuracies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om0h-LXQaYgd"
      },
      "outputs": [],
      "source": [
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy [N=5]', path=results_path + 'test_accuracy_5_rnn.png')\n",
        "\n",
        "# Average accuracy over all Steps\n",
        "print(f\"Average test accuracy: {np.mean(test_accuracies):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZYIMAkPaYge"
      },
      "source": [
        "### Task 2: Vanilla RNN in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7zN5CzpaYge"
      },
      "outputs": [],
      "source": [
        "# Train the model on T=10\n",
        "model, losses, accuracies = train(config, input_length=p1[1], type='RNN', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss [N=10]', path=results_path + 'training_loss_10_rnn.png')\n",
        "\n",
        "# Plot the accuracies\n",
        "plot_accuracy(accuracies, title='Training Accuracy [N=10]', path=results_path + 'training_accuracy_10_rnn.png')"
      ],
      "metadata": {
        "id": "PAtNMHEtIHCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnXzLE44aYge"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[1], config=config, device=device)\n",
        "# Add accuracies\n",
        "p2_acc_rnn.append(np.mean(test_accuracies))\n",
        "\n",
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy [N=10]', path=results_path + 'test_accuracy_10_rnn.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na4yD_T2aYge"
      },
      "outputs": [],
      "source": [
        "# Train the model on T=15\n",
        "model, losses, accuracies = train(config, input_length=p1[2], type='RNN', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss [N=15]', path=results_path + 'training_loss_15_rnn.png')\n",
        "\n",
        "# Plot the accuracies\n",
        "plot_accuracy(accuracies, title='Training Accuracy [N=15]', path=results_path + 'training_accuracy_15_rnn.png')"
      ],
      "metadata": {
        "id": "R5KlWue0ICOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7kJlHO_aYge"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[2], config=config, device=device)\n",
        "# Add accuracies\n",
        "p2_acc_rnn.append(np.mean(test_accuracies))\n",
        "\n",
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy [N=15]', path=results_path + 'test_accuracy_15_rnn.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FceW-_vnaYge"
      },
      "outputs": [],
      "source": [
        "# Train the model on T=20\n",
        "model, losses, accuracies = train(config, input_length=p1[3], type='RNN', device=device)\n",
        "# Add accuracies\n",
        "p2_acc_rnn.append(np.mean(accuracies))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss [N=20]', path=results_path + 'training_loss_20_rnn.png')\n",
        "\n",
        "# Plot the accuracies\n",
        "plot_accuracy(accuracies, title='Training Accuracy [N=20]', path=results_path + 'training_accuracy_20_rnn.png')"
      ],
      "metadata": {
        "id": "bmxWG5-nH8P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N50w9XFgaYge"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[3], config=config, device=device)\n",
        "\n",
        "# Add accuracies\n",
        "p2_acc_rnn.append(np.mean(test_accuracies))\n",
        "\n",
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy [N=20]', path=results_path + 'test_accuracy_20_rnn.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8j-5cD7aYge"
      },
      "source": [
        "### Task 3: Long-Short Term Network (LSTM) in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BpiglOPaYge"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, seq_length, input_dim, num_hidden, num_classes, batch_size=128, device=None):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.seq_length = seq_length\n",
        "        self.input_dim = input_dim\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        if device is None:\n",
        "          device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # Hidden Layer\n",
        "        self.W_gx = nn.Parameter(torch.Tensor(self.input_dim, self.num_hidden))\n",
        "        self.W_gh = nn.Parameter(torch.Tensor(self.num_hidden, self.num_hidden))\n",
        "        self.B_g = nn.Parameter(torch.Tensor(self.num_hidden))\n",
        "\n",
        "        # Cell State\n",
        "        # (1) Input gate\n",
        "        self.W_ix = nn.Parameter(torch.Tensor(self.input_dim, self.num_hidden))\n",
        "        self.W_ih = nn.Parameter(torch.Tensor(self.num_hidden, self.num_hidden))\n",
        "        self.B_i = nn.Parameter(torch.Tensor(self.num_hidden))\n",
        "\n",
        "        # (2) Forget gate\n",
        "        self.W_fx = nn.Parameter(torch.Tensor(self.input_dim, self.num_hidden))\n",
        "        self.W_fh = nn.Parameter(torch.Tensor(self.num_hidden, self.num_hidden))\n",
        "        self.B_f = nn.Parameter(torch.Tensor(self.num_hidden))\n",
        "\n",
        "        # (3) Output gate\n",
        "        self.W_ox = nn.Parameter(torch.Tensor(self.input_dim, self.num_hidden))\n",
        "        self.W_oh = nn.Parameter(torch.Tensor(self.num_hidden, self.num_hidden))\n",
        "        self.B_o = nn.Parameter(torch.Tensor(self.num_hidden))\n",
        "\n",
        "        # Output Layer\n",
        "        self.W_ph = nn.Parameter(torch.Tensor(self.num_hidden, self.num_classes))\n",
        "        self.B_y = nn.Parameter(torch.Tensor(self.num_classes))\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state and cell state\n",
        "        h_t = torch.zeros(self.batch_size, self.num_hidden, device=self.device)\n",
        "        c_t = torch.zeros(self.batch_size, self.num_hidden, device=self.device)\n",
        "\n",
        "        for t in range(self.seq_length):\n",
        "            x_t = x[:, t].view(self.batch_size, -1)\n",
        "\n",
        "            # Compute the hidden state\n",
        "            g_t = torch.tanh(x_t @ self.W_gx + h_t @ self.W_gh + self.B_g)\n",
        "            i_t = torch.sigmoid(x_t @ self.W_ix + h_t @ self.W_ih + self.B_i)\n",
        "            f_t = torch.sigmoid(x_t @ self.W_fx + h_t @ self.W_fh + self.B_f)\n",
        "            o_t = torch.sigmoid(x_t @ self.W_ox + h_t @ self.W_oh + self.B_o)\n",
        "\n",
        "            c_t = f_t * c_t + i_t * g_t\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        # Compute the output\n",
        "        output = h_t @ self.W_ph + self.B_y\n",
        "        y = torch.softmax(output, dim=1)\n",
        "        return y\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\" Keep weights in a similar range to avoid\n",
        "            gradients vanishing or exploding.\n",
        "        \"\"\"\n",
        "        # Initialize weights\n",
        "        nn.init.xavier_normal_(self.W_gx)\n",
        "        nn.init.xavier_normal_(self.W_gh)\n",
        "        nn.init.xavier_normal_(self.W_ix)\n",
        "        nn.init.xavier_normal_(self.W_ih)\n",
        "        nn.init.xavier_normal_(self.W_fx)\n",
        "        nn.init.xavier_normal_(self.W_fh)\n",
        "        nn.init.xavier_normal_(self.W_ox)\n",
        "        nn.init.xavier_normal_(self.W_oh)\n",
        "        nn.init.xavier_normal_(self.W_ph)\n",
        "        nn.init.zeros_(self.B_g)\n",
        "        nn.init.zeros_(self.B_i)\n",
        "        nn.init.zeros_(self.B_f)\n",
        "        nn.init.zeros_(self.B_o)\n",
        "        nn.init.zeros_(self.B_y)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Initialize hidden state\n",
        "        self.hidden_state = torch.zeros(self.batch_size, self.self.num_hidden, device=self.device)\n",
        "\n",
        "    def set_grad(self, requires_grad):\n",
        "        # Set requires_grad for all parameters\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOSGeJ96aYge"
      },
      "outputs": [],
      "source": [
        "# Train the model T=5\n",
        "model, losses, accuracies = train(config, input_length=p1[0], type='LSTM', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss [N=5]', path=results_path + 'training_loss_5_lstm.png')\n"
      ],
      "metadata": {
        "id": "8OsCmrorHVjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracies\n",
        "plot_accuracy(accuracies, title='Training Accuracy [N=5]', path=results_path + 'training_accuracy_5_lstm.png')"
      ],
      "metadata": {
        "id": "MXTxRWzxHTWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsFlv_X3aYge"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[0], config=config, device=device)\n",
        "\n",
        "# Add accuracies\n",
        "p3_acc_lstm.append(np.mean(test_accuracies))\n",
        "\n",
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy [N=5]', path=results_path + 'test_accuracy_5_lstm.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz3mfUUIaYge"
      },
      "outputs": [],
      "source": [
        "# Train the model T=10\n",
        "model, losses, accuracies = train(config, input_length=p1[1], type='LSTM', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss [N=10]', path=results_path + 'training_loss_10_lstm.png')"
      ],
      "metadata": {
        "id": "BjXXiBlUHZW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracies\n",
        "plot_accuracy(accuracies, title='Training Accuracy [N=10]', path=results_path + 'training_accuracy_10_lstm.png')"
      ],
      "metadata": {
        "id": "gc7QjHJWHa3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rei6kls2aYge"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[1], config=config, device=device)\n",
        "\n",
        "# Add accuracies\n",
        "p3_acc_lstm.append(np.mean(test_accuracies))\n",
        "\n",
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy  [N=10]', path=results_path + 'test_accuracy_10_lstm.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQFThC2IaYge"
      },
      "outputs": [],
      "source": [
        "# Train the model T=15\n",
        "model, losses, accuracies = train(config, input_length=p1[2], type='LSTM', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss  [N=15]', path=results_path + 'training_loss_15_lstm.png')\n",
        "\n",
        "# Plot the accuracies\n",
        "plot_accuracy(accuracies, title='Training Accuracy [N=15]', path=results_path + 'training_accuracy_15_lstm.png')"
      ],
      "metadata": {
        "id": "xP0GblGzHemr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CI6OCTvaYge"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[2], config=config, device=device)\n",
        "\n",
        "# Add accuracies\n",
        "p3_acc_lstm.append(np.mean(test_accuracies))\n",
        "\n",
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy [N=15]', path=results_path + 'test_accuracy_15_lstm.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mnyQw6UaYgf"
      },
      "outputs": [],
      "source": [
        "# Train the model T=20\n",
        "model, losses, accuracies = train(config, input_length=p1[3], type='LSTM', device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plot_loss(losses, title='Training Loss [N=20]', path=results_path + 'training_loss_20_lstm.png')\n",
        "\n",
        "# Plot the accuracies\n",
        "plot_accuracy(accuracies, title='Training Accuracy [N=20]', path=results_path + 'training_accuracy_20_lstm.png')"
      ],
      "metadata": {
        "id": "iSX38UjqHh_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07Osuf0HaYgf"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_accuracies = test(model, input_length=p1[3], config=config, device=device)\n",
        "\n",
        "# Add accuracies\n",
        "p3_acc_lstm.append(np.mean(test_accuracies))\n",
        "\n",
        "# plot the test accuracies\n",
        "plot_accuracy(test_accuracies, title='Test Accuracy [N=20]', path=results_path + 'test_accuracy_20_lstm.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdfxZzPyaYgf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()  # Apply seaborn styles for better visual appeal\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))  # Increase the figure size for better visibility\n",
        "\n",
        "ax.scatter(p1, p2_acc_rnn, color='red', label='RNN')\n",
        "ax.scatter(p1, p3_acc_lstm, color='green', label='LSTM')\n",
        "\n",
        "# Add lines between the scatter points\n",
        "ax.plot(p1, p2_acc_rnn, color='red', linestyle='--')\n",
        "ax.plot(p1, p3_acc_lstm, color='green', linestyle='--')\n",
        "\n",
        "ax.set_title('Accuracy with Respect to Palindromes Length', fontsize=16)\n",
        "ax.set_xlabel('Palindromes Length', fontsize=14)\n",
        "ax.set_ylabel('Accuracy', fontsize=14)\n",
        "ax.legend(fontsize=14)\n",
        "\n",
        "# Add gridlines for better readability\n",
        "ax.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-py11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.-1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}